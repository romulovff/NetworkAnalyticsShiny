g.invites <- graph_from_data_frame(dt.invites, directed = TRUE, vertices = dt.users)
summary(g.invites)
cat("The longest chain is", farthest_vertices(g.invites)$distance, ".")
cat("The clustering coefficient is", transitivity(g.invites), ".\n\nThe clustering coefficient is computed by dividing the number of links among neighbours of a node by the possible links among neighbours of that node. Since only one invite per person can be accepted, there will not be any links among neighbours of any node, resulting in this coefficient being always equal to zero in this network.")
# Length of all the shortest paths between vertices
dt.path <- data.table(count = distance_table(g.invites, directed = TRUE)$res)
dt.path <- cbind(path_length = rownames(dt.path), dt.path)
rownames(dt.path) <- 1:nrow(dt.path)
# Plotting the distribution of the length of all the shortest paths between vertices
ggplot(dt.path, aes(x = path_length, y = count)) + geom_bar(stat = "identity")
# Computing the mean length of the paths between vertices
mean.length <- mean_distance(g.invites, directed = TRUE, unconnected = TRUE)
cat("Yes, we can observe the same cascade behaviour in the invites network as Goel, Watts and Goldstein observed in online networks. Out of", sum(dt.path$count), "cascades only", sum(dt.path$count[dt.path$path_length >= 7]), "had a length of seven or higher (", round(sum(dt.path$count[dt.path$path_length >= 7])/sum(dt.path$count)*100, digits = 2), "%). The majority of instances show no difusion at all (", round(sum(dt.path$count[dt.path$path_length == 1])/sum(dt.path$count)*100, digits = 2), "%). The size distribution of diffusion events is right-skewed and heavy-tailed just as mentioned in the paper with the mean length of cascades being equal to", mean.length, ".")
# Retrieving only the rows without NAs in the user_id and inviter_id columns
dt.network.gender <- na.omit(dt.users, cols = c("user_id", "inviter_id", "gender"))
# Creating a dataframe with the edge list in the first two columns
dt.invites.gender <- dt.network.gender[, 2:1]
# Creating igraph directed graph
g.gender <- graph_from_data_frame(dt.invites.gender, directed = TRUE, vertices = dt.users)
# Changing gender from categorical to numeric to compute assortivity measure (could have used assortativity_nominal instead)
gender <- as.numeric(factor(V(g.gender)$gender))
# Computing assortivity coefficient
gender.assortivity <- assortativity(g.gender, gender, directed = TRUE)
# Similar steps were taken for the age assortivity
dt.network.age <- na.omit(dt.users, cols = c("user_id", "inviter_id", "birth_year"))
dt.invites.age <- dt.network.age[ ,2:1]
g.age <- graph_from_data_frame(dt.invites.age, directed = TRUE, vertices = dt.users)
age <- factor(V(g.age)$birth_year)
age.assortivity <- assortativity(g.age, age, directed = TRUE)
cat("The assortivity coefficient measures the level of homophily of the graph based on some vertex labeling or values assigned to vertices. The assortivity coefficient considering gender is", gender.assortivity, "which is a positive value, meaning that men are more likely to invite other men and that women are more likely to invite other women. The assortivity coefficient considering age is", age.assortivity, "which is a positive value, meaning that people tend to invite other people that are close in age. Gender assortivity is lower than age assortivity meaning that the likelihood that people invite other people that are close in age is higher than that of the same gender.")
# <Answer here>
g.likes <- graph_from_data_frame(dt.likes, directed=TRUE, vertices=NULL)
summary(g.likes)
cat("The clustering coefficient is", transitivity(g.likes), "\n\nIt is very low clustering coefficient signalling that the chance that two people like the same person is very low.")
dt.user.gender <- dt.users[, c("user_id","gender")]
dt.likes.gender <- merge(dt.likes, dt.user.gender, by.x = "sender_user_id", by.y = "user_id")
dt.likes.gender <- merge(dt.likes.gender, dt.user.gender, by.x = "receiver_user_id", by.y = "user_id")
colnames(dt.likes.gender)[4] <- "sender_gender"
colnames(dt.likes.gender)[5] <- "receiver_gender"
dt.female.mutual.likes <- dt.likes.gender[dt.likes.gender$receiver_gender == "Female" & dt.likes.gender$sender_gender == "Female"]
dt.male.mutual.likes <- dt.likes.gender[dt.likes.gender$receiver_gender == "Male" & dt.likes.gender$sender_gender == "Male"]
cat("The number of likes among females is", nrow(dt.female.mutual.likes), ", equating to", round(nrow(dt.female.mutual.likes)/nrow(dt.likes.gender[dt.likes.gender$sender_gender == "Female"])*100, digits = 2), "% of all likes sent by females.\n")
cat("The number of likes among males is", nrow(dt.male.mutual.likes), ", equating to", round(nrow(dt.male.mutual.likes)/nrow(dt.likes.gender[dt.likes.gender$sender_gender == "Male"])*100, digits = 2), "% of all likes sent by males.\n")
cat("The number of individidual females liking other females is", length(unique(dt.female.mutual.likes$sender_user_id)),".\n")
cat("The number of individidual males liking other males is", length(unique(dt.male.mutual.likes$sender_user_id)),".\n")
cat("In absolute terms, fewer women-to-women likes were sent than men-to-men. In relative terms, more women-to-women likes were sent than men-to-men.")
g.mutual.likes <- as.undirected(g.likes, mode = "mutual")
cat("The clustering coefficient is", transitivity(g.mutual.likes), ".\n\nIt is an extremelly low clustering coefficient, signalling that the chance that two people share mutual likes with a third person is almost 0.")
ggplot() + geom_histogram(aes(x = degree(g.likes)))
cat("A random network is characterized by having a degree distribution which follows a normal distribution. For this reason, there is no clustering in random networks.\nA free-scale network is characterized by having a degree distribution which roughly follows a power law distribution. For this reason, most nodes will have a very low level of connectivity while nodes with large numbers of edges appear in small quantity at every scale, resulting in a highly centralized network.\nA mixed network has fewer and smaller clusters than a scale-free network, the distribution of nodes has a scale and does not follow a pure power law.\nBased on the Quanta Magazine article, our network of matches would resemble a mixed network as most users cluster around the median and the tail of the distribution is weak.")
# <Answer here>
# Retrieving only the rows without NAs in the user_id and inviter_id columns
dt.network.gender <- na.omit(dt.users, cols = c("user_id", "inviter_id", "gender"))
library(data.table)
library(ggplot2)
library(igraph)
load("nda-dating-likes.RData")
dt.network <- na.omit(dt.users, cols = c("user_id", "inviter_id"))
dt.invites <- dt.network[, 2:1]
g.invites <- graph_from_data_frame(dt.invites, directed = TRUE, vertices = dt.users)
summary(g.invites)
cat("The longest chain is", farthest_vertices(g.invites)$distance, ".")
cat("The clustering coefficient is", transitivity(g.invites), ".\n\nThe clustering coefficient is computed by dividing the number of links among neighbours of a node by the possible links among neighbours of that node. Since only one invite per person can be accepted, there will not be any links among neighbours of any node, resulting in this coefficient being always equal to zero in this network.")
# Length of all the shortest paths between vertices
dt.path <- data.table(count = distance_table(g.invites, directed = TRUE)$res)
dt.path <- cbind(path_length = rownames(dt.path), dt.path)
rownames(dt.path) <- 1:nrow(dt.path)
# Plotting the distribution of the length of all the shortest paths between vertices
ggplot(dt.path, aes(x = path_length, y = count)) + geom_bar(stat = "identity")
# Computing the mean length of the paths between vertices
mean.length <- mean_distance(g.invites, directed = TRUE, unconnected = TRUE)
cat("Yes, we can observe the same cascade behaviour in the invites network as Goel, Watts and Goldstein observed in online networks. Out of", sum(dt.path$count), "cascades only", sum(dt.path$count[dt.path$path_length >= 7]), "had a length of seven or higher (", round(sum(dt.path$count[dt.path$path_length >= 7])/sum(dt.path$count)*100, digits = 2), "%). The majority of instances show no difusion at all (", round(sum(dt.path$count[dt.path$path_length == 1])/sum(dt.path$count)*100, digits = 2), "%). The size distribution of diffusion events is right-skewed and heavy-tailed just as mentioned in the paper with the mean length of cascades being equal to", mean.length, ".")
# Retrieving only the rows without NAs in the user_id and inviter_id columns
dt.network.gender <- na.omit(dt.users, cols = c("user_id", "inviter_id", "gender"))
# Creating a dataframe with the edge list in the first two columns
dt.invites.gender <- dt.network.gender[, 2:1]
# Creating igraph directed graph
g.gender <- graph_from_data_frame(dt.invites.gender, directed = TRUE, vertices = dt.users)
# Changing gender from categorical to numeric to compute assortivity measure (could have used assortativity_nominal instead)
gender <- as.numeric(factor(V(g.gender)$gender))
# Computing assortivity coefficient
gender.assortativity <- assortativity(g.gender, gender, directed = TRUE)
# Similar steps were taken for the age assortivity
dt.network.age <- na.omit(dt.users, cols = c("user_id", "inviter_id", "birth_year"))
dt.invites.age <- dt.network.age[ ,2:1]
g.age <- graph_from_data_frame(dt.invites.age, directed = TRUE, vertices = dt.users)
age <- factor(V(g.age)$birth_year)
age.assortativity <- assortativity(g.age, age, directed = TRUE)
cat("The assortativity coefficient measures the level of homophily of the graph based on some vertex labeling or values assigned to vertices. The assortativity coefficient considering gender is", gender.assortativity, "which is a positive value, meaning that men are more likely to invite other men and that women are more likely to invite other women. The assortativity coefficient considering age is", age.assortativity, "which is a positive value, meaning that people tend to invite other people that are close in age. Gender assortativity is lower than age assortativity meaning that the likelihood that people invite other people that are close in age is higher than that of the same gender.")
# <Answer here>
g.likes <- graph_from_data_frame(dt.likes, directed=TRUE, vertices=NULL)
summary(g.likes)
cat("The clustering coefficient is", transitivity(g.likes), "\n\nIt is very low clustering coefficient signalling that the chance that two people like the same person is very low.")
dt.user.gender <- dt.users[, c("user_id","gender")]
dt.likes.gender <- merge(dt.likes, dt.user.gender, by.x = "sender_user_id", by.y = "user_id")
dt.likes.gender <- merge(dt.likes.gender, dt.user.gender, by.x = "receiver_user_id", by.y = "user_id")
colnames(dt.likes.gender)[4] <- "sender_gender"
colnames(dt.likes.gender)[5] <- "receiver_gender"
dt.female.mutual.likes <- dt.likes.gender[dt.likes.gender$receiver_gender == "Female" & dt.likes.gender$sender_gender == "Female"]
dt.male.mutual.likes <- dt.likes.gender[dt.likes.gender$receiver_gender == "Male" & dt.likes.gender$sender_gender == "Male"]
cat("The number of likes among females is", nrow(dt.female.mutual.likes), ", equating to", round(nrow(dt.female.mutual.likes)/nrow(dt.likes.gender[dt.likes.gender$sender_gender == "Female"])*100, digits = 2), "% of all likes sent by females.\n")
cat("The number of likes among males is", nrow(dt.male.mutual.likes), ", equating to", round(nrow(dt.male.mutual.likes)/nrow(dt.likes.gender[dt.likes.gender$sender_gender == "Male"])*100, digits = 2), "% of all likes sent by males.\n")
cat("The number of individidual females liking other females is", length(unique(dt.female.mutual.likes$sender_user_id)),".\n")
cat("The number of individidual males liking other males is", length(unique(dt.male.mutual.likes$sender_user_id)),".\n")
cat("In absolute terms, fewer women-to-women likes were sent than men-to-men. In relative terms, more women-to-women likes were sent than men-to-men.")
g.mutual.likes <- as.undirected(g.likes, mode = "mutual")
cat("The clustering coefficient is", transitivity(g.mutual.likes), ".\n\nIt is an extremelly low clustering coefficient, signalling that the chance that two people share mutual likes with a third person is almost 0.")
ggplot() + geom_histogram(aes(x = degree(g.likes)))
cat("A random network is characterized by having a degree distribution which follows a normal distribution. For this reason, there is no clustering in random networks.\nA free-scale network is characterized by having a degree distribution which roughly follows a power law distribution. For this reason, most nodes will have a very low level of connectivity while nodes with large numbers of edges appear in small quantity at every scale, resulting in a highly centralized network.\nA mixed network has fewer and smaller clusters than a scale-free network, the distribution of nodes has a scale and does not follow a pure power law.\nBased on the Quanta Magazine article, our network of matches would resemble a mixed network as most users cluster around the median and the tail of the distribution is weak.")
# <Answer here>
dt.network <- na.omit(dt.users, cols = c("user_id", "inviter_id"))
dt.invites <- dt.network[, 2:1]
g.invites <- graph_from_data_frame(dt.invites, directed = TRUE, vertices = dt.users)
summary(g.invites)
cat("The longest chain is", farthest_vertices(g.invites)$distance, ".")
cat("The clustering coefficient is", transitivity(g.invites), ".\n\nThe clustering coefficient is computed by dividing the number of links among neighbors of a node by the possible links among neighbors of that node. Since only one invite per person can be accepted, there will not be any links among neighbors of any node, resulting in this coefficient being always equal to zero in this network.")
# Retrieving only the rows without NAs in the user_id and inviter_id columns
dt.network.gender <- na.omit(dt.users, cols = c("user_id", "inviter_id", "gender"))
# Creating a dataframe with the edge list in the first two columns
dt.invites.gender <- dt.network.gender[, 2:1]
# Creating igraph directed graph
g.gender <- graph_from_data_frame(dt.invites.gender, directed = TRUE, vertices = dt.users)
# Changing gender from categorical to numeric to compute assortivity measure (could have used assortativity_nominal instead)
gender <- as.numeric(factor(V(g.gender)$gender))
# Computing assortivity coefficient
gender.assortativity <- assortativity(g.gender, gender, directed = TRUE)
# Similar steps were taken for the age assortivity
dt.network.age <- na.omit(dt.users, cols = c("user_id", "inviter_id", "birth_year"))
dt.invites.age <- dt.network.age[ ,2:1]
g.age <- graph_from_data_frame(dt.invites.age, directed = TRUE, vertices = dt.users)
age <- factor(V(g.age)$birth_year)
age.assortativity <- assortativity(g.age, age, directed = TRUE)
cat("The assortativity coefficient measures the level of homophily of the graph based on some vertex labeling or values assigned to vertices. The assortativity coefficient considering gender is", gender.assortativity, "which is a positive value, meaning that men are more likely to invite other men and that women are more likely to invite other women. The assortativity coefficient considering age is", age.assortativity, "which is a positive value, meaning that people tend to invite other people that are close in age. Gender assortativity is lower than age assortativity meaning that the likelihood that people invite other people that are close in age is higher than that of the same gender.")
g.likes <- graph_from_data_frame(dt.likes, directed=TRUE, vertices=NULL)
summary(g.likes)
cat("The clustering coefficient is", transitivity(g.likes), "\n\nIt is very low clustering coefficient signaling that the chance that two people like the same person is very low.")
install.packages(rsconnect)
install.packages("rsconnect")
rsconnect::setAccountInfo(name='maria-ferreira-50465', token='F20DCC264DDE0B81C4FFCAB502AF166E', secret='TBuMVrUwoEUHr4EyHXQ24qPl9sw7MwevPBsUiair')
library(rsconnect)
rsconnect::deployApp('path/to/your/app')
install.packages(c('ggplot2', 'shiny'))
library(shiny)
library(ggplot2)
function(input, output) {
dataset <- reactive({
diamonds[sample(nrow(diamonds), input$sampleSize),]
})
output$plot <- renderPlot({
p <- ggplot(dataset(), aes_string(x=input$x, y=input$y)) + geom_point()
if (input$color != 'None')
p <- p + aes_string(color=input$color)
facets <- paste(input$facet_row, '~', input$facet_col)
if (facets != '. ~ .')
p <- p + facet_grid(facets)
if (input$jitter)
p <- p + geom_jitter()
if (input$smooth)
p <- p + geom_smooth()
print(p)
}, height=700)
}
library(shiny)
library(ggplot2)
dataset <- diamonds
fluidPage(
titlePanel("Diamonds Explorer"),
sidebarPanel(
sliderInput('sampleSize', 'Sample Size', min=1, max=nrow(dataset),
value=min(1000, nrow(dataset)), step=500, round=0),
selectInput('x', 'X', names(dataset)),
selectInput('y', 'Y', names(dataset), names(dataset)[[2]]),
selectInput('color', 'Color', c('None', names(dataset))),
checkboxInput('jitter', 'Jitter'),
checkboxInput('smooth', 'Smooth'),
selectInput('facet_row', 'Facet Row', c(None='.', names(dataset))),
selectInput('facet_col', 'Facet Column', c(None='.', names(dataset)))
),
mainPanel(
plotOutput('plot')
)
)
library(shiny)
runApp()
runApp('Project-Shinny-App')
library(rsconnect)
deployApp()
load("~/Mestrado/Network Analytics/Group assignment/nda-assignment-similarity/nda-similarity-anon.RData")
dt.books.categories <- data.table[dt.books[,list(n_cat = .N), by=categories]]
library(data.table)
library(ggplot2)
library(igraph)
library(stringr)
dt.books <- read.csv(file = "books.csv")
dt.books <- data.table(dt.books[,c("title","authors","categories","published_year","average_rating")])
dt.books[,"title"] = str_to_lower(dt.books[,"title"])
dt.books[,"authors"] = str_to_title(dt.books[,"authors"])
View(dt.books)
dt.books.categories <- data.table[dt.books[,list(n_cat = .N), by=categories]]
library(data.table)
library(ggplot2)
library(igraph)
library(stringr)
dt.books <- read.csv(file = "books.csv")
View(dt.books)
library(data.table)
library(ggplot2)
library(igraph)
library(stringr)
dt.books <- read.csv(file = "books.csv")
dt.books <- data.table(dt.books[,c("title","authors","categories","published_year","average_rating")])
dt.books[,"title"] = str_to_lower(dt.books[,"title"])
dt.books[,"authors"] = str_to_title(dt.books[,"authors"])
View(dt.books)
dt.books.categories <- data.table[dt.books[,list(n_cat = .N), by=categories]]
dt.books <- read.csv(file = "books.csv")
dt.books <- read.csv("books.csv")
dt.books <- read.csv("books.csv")
dt.books <- read.csv("books.csv")
dt.books <- read.csv("books.csv")
dt.books <- read.csv("books.csv")
dt.books <- read.csv(file = "books.csv")
f <- file.choose()
f
dt.books <- read.csv("C:\\Users\\Maria Ferreira\\Documents\\Project-Shinny-App\\books.csv")
View(dt.books)
shiny::runApp('C:/Users/Maria Ferreira/Desktop/myApp')
install.packages("shinythemes")
runApp('C:/Users/Maria Ferreira/Desktop/myApp')
runApp('C:/Users/Maria Ferreira/Desktop/myApp')
runApp('C:/Users/Maria Ferreira/Desktop/myApp')
runApp('C:/Users/Maria Ferreira/Desktop/myApp')
runApp('C:/Users/Maria Ferreira/Desktop/myApp')
runApp('C:/Users/Maria Ferreira/Desktop/myApp')
runApp('C:/Users/Maria Ferreira/Desktop/myApp')
runApp('C:/Users/Maria Ferreira/Desktop/myApp')
runApp('C:/Users/Maria Ferreira/Desktop/myApp')
library(data.table)
library(ggplot2)
library(igraph)
library(shiny)
# library(readxl)
library(openxlsx)
dt.books <- read.xlsx("dt.books.clean.xlsx")
dt.books <- dt.books[,c("title", "authors", "categories", "published_year", "average_rating")]
# Creating the column avg_rating_class that tells for each BOOK the rating that they are in
dt.books$avg_rating_class <- with(dt.books, ifelse(average_rating >= 0 & average_rating < 0.5, "[0-0.5[", ifelse(average_rating >= 0.5 & average_rating < 1, "[0.5 -1[", ifelse(average_rating >= 1 & average_rating < 1.5, "[1-1.5[", ifelse(average_rating >= 1.5 & average_rating < 2, "[1.5-2[", ifelse(average_rating >= 2 & average_rating <= 2.5, "[2-2.5]", ifelse(average_rating >= 2.5 & average_rating <= 3, "[2.5-3[", ifelse(average_rating >= 3 & average_rating <= 3.5, "[3-3.5[", ifelse(average_rating >= 3.5 & average_rating <= 4,  "[3.5-4[", ifelse(average_rating >= 4 & average_rating <= 4.5,  "[4-4.5[", ifelse(average_rating >= 4.5 & average_rating <= 5,  "[4.5-5]", "NA")))))))))))
# Creating the column avg_rating_individual that tells for each AUTHOR the rating that they are in (by doing the average of all their books)
average.ratings <- vector()
for (author in dt.books$authors) {
the_author <- dt.books[dt.books$authors %in% author, ]
average_rating_author <- mean(the_author$average_rating)
average.ratings <- c(average.ratings, average_rating_author)
}
dt.books$avg_rating_individual <- average.ratings
# Creating the column avg_rating_individual_class that tells for each AUTHOR the rating that they are in (same as above but with new column)
dt.books$avg_rating_individual_class <- with(dt.books, ifelse(avg_rating_individual >= 0 & avg_rating_individual < 0.5, "[0-0.5[", ifelse(avg_rating_individual >= 0.5 & avg_rating_individual < 1, "[0.5 -1[", ifelse(avg_rating_individual >= 1 & avg_rating_individual < 1.5, "[1-1.5[", ifelse(avg_rating_individual >= 1.5 & avg_rating_individual < 2, "[1.5-2[", ifelse(avg_rating_individual >= 2 & avg_rating_individual <= 2.5, "[2-2.5]", ifelse(avg_rating_individual >= 2.5 & avg_rating_individual <= 3, "[2.5-3[", ifelse(avg_rating_individual >= 3 & avg_rating_individual <= 3.5, "[3-3.5[", ifelse(avg_rating_individual >= 3.5 & avg_rating_individual <= 4,  "[3.5-4[", ifelse(avg_rating_individual >= 4 & avg_rating_individual <= 4.5,  "[4-4.5[", ifelse(avg_rating_individual >= 4.5 & avg_rating_individual <= 5,  "[4.5-5]", "NA")))))))))))
main.categories <- vector()
for (author in dt.books$author) {
the_author <- dt.books[dt.books$authors %in% author, ]
main.category <- names(sort(table(the_author$categories), decreasing=TRUE)[1])
main.categories <- c(main.categories, main.category)
}
dt.books$main_category <- main.categories
set.seed(150)
dict.colors.categories <- hash()
for (category in unique(dt.books$categories)) {
dict.colors.categories[[category]] <- as.character(randomColor(luminosity="bright"))
}
dt.colors <- data.frame(Col1=c(keys(dict.colors.categories)), Col2=c(values(dict.colors.categories)),
stringsAsFactors=FALSE)
dict.colors.rating <- hash()
for (rating_class in unique(dt.books$avg_rating_class)) {
dict.colors.rating[[rating_class]] <- as.character(randomColor(luminosity="bright"))
}
dt.colors.avg.rating <- data.frame(Col1=c(keys(dict.colors.rating)), Col2=c(values(dict.colors.rating)),
stringsAsFactors=FALSE)
save(dt.colors, file="books.RData")
save(dt.books, file="books.RData")
library(data.table)
library(igraph)
library(ggplot2)
library(shiny)
library(dplyr)
library(hash)
library(randomcoloR)
author.avg.rank <- function(author.name, year.range) {
dt.books.range <- filter(dt.books, published_year >= min(year.range) & published_year <= max(year.range))
dt.author <- dt.books.range[dt.books.range$authors == author.name,]
average_rating_author <- mean(dt.author$average_rating)
round(average_rating_author,3)
}
get.unique.authors <- function() {
unique(dt.books$authors)
}
get.authors.most.books <- function(number.authors, year.range) {
dt.books.range <- filter(dt.books, published_year >= min(year.range) & published_year <= max(year.range))
dt.authors.books <- dt.books.range %>% count(authors, sort = TRUE)
dt.authors.books[1:number.authors,]
}
get.average.book.rating <- function(year.range) {
dt.books.range <- filter(dt.books, published_year >= min(year.range) & published_year <= max(year.range))
round(mean(dt.books.range$average_rating, na.rm = TRUE),3)
}
get.categories.most.books <- function(number.categories, year.range) {
dt.books.range <- filter(dt.books, published_year >= min(year.range) & published_year <= max(year.range))
dt.categories.books <- dt.books.range %>% count(categories, sort = TRUE)
dt.categories.books[1:number.categories,]
}
get.books.highest.rating <- function(number.books, year.range) {
dt.books.range <- filter(dt.books, published_year >= min(year.range) & published_year <= max(year.range))
dt.books.range %>% slice_max(average_rating, n = number.books, with_ties = FALSE)
}
get.books.count.year.range <- function(year.range) {
dt.books.range <- filter(dt.books, published_year >= min(year.range) & published_year <= max(year.range))
length(unique(dt.books.range$title))
}
get.authors.count.year.range <- function(year.range) {
dt.books.range <- filter(dt.books, published_year >= min(year.range) & published_year <= max(year.range))
length(unique(dt.books.range$authors))
}
get.distinct.author.per.category <- function(year.range) {
dt.books.range <- filter(dt.books, published_year >= min(year.range) & published_year <= max(year.range))
dt.category.number <- aggregate(data = dt.books.range,
authors ~ categories,
function(authors) length(unique(authors)))
dt.category.number[order(-dt.category.number$authors),]
}
plot.books.published.by.year <- function(year.range) {
dt.books.range <- filter(dt.books, published_year >= min(year.range) & published_year <= max(year.range))
ggplot(dt.books.range, aes(x=published_year)) + geom_bar() + ggtitle('Books per Year')
}
plot.distinct.authors.by.year <- function(year.range) {
dt.books.range <- filter(dt.books, published_year >= min(year.range) & published_year <= max(year.range))
dt.author.number <- aggregate(data = dt.books.range,
authors ~ published_year,
function(authors) length(unique(authors)))
ggplot(dt.author.number, aes(x=published_year, y=authors)) + geom_bar(stat="identity") + ggtitle('Distinct Authors per Year')
}
plot.books.by.ranking <- function(year.range) {
dt.books.range <- filter(dt.books, published_year >= min(year.range) & published_year <= max(year.range))
ggplot(dt.books.range,aes(x=average_rating)) + geom_histogram() +  ggtitle('Books per Ranking')
}
plot.books.by.authornumber <- function(year.range) {
dt.books.range <- filter(dt.books, published_year >= min(year.range) & published_year <= max(year.range))
dt.authors.number <- dt.books.range %>% count(title, sort = TRUE)
ggplot(dt.authors.number,aes(x=n)) + geom_histogram() +  ggtitle('Books per Number of Authors')
}
## INDIVIDUAL NETWORKS
plot.author.to.books.network <- function(author.name, year.range) {
dt.books.range <- filter(dt.books, published_year >= min(year.range) & published_year <= max(year.range))
dt.author <- dt.books.range[dt.books.range$authors == author.name, ]
dt.author.books <- dt.author[, c("title", "authors")][2:1]
dt.author.books <- dt.author.books[!duplicated(dt.author.books), ]
g.author.to.books.network <- graph.data.frame(dt.author.books, directed = TRUE)
plot(g.author.to.books.network)
}
# Aqui talvez fizesse sentido a introdu??o de pesos
plot.author.to.categories.network <- function(author.name, year.range) {
dt.books.range <- filter(dt.books, published_year >= min(year.range) & published_year <= max(year.range))
dt.author <- dt.books.range[dt.books.range$authors == author.name, ]
dt.author.categories <- dt.author[, c("categories", "authors")][2:1]
# No caso de se introduzir pesos, aqui n?o se remove duplicados
dt.author.categories <- dt.author.categories[!duplicated(dt.author.categories), ]
g.author.to.categories.network <- graph.data.frame(dt.author.categories, directed = TRUE)
plot(g.author.to.categories.network)
}
plot.similar.rank.authors <- function(author.name, year.range, top.n.values) {
dt.books.range <- filter(dt.books, published_year >= min(year.range) & published_year <= max(year.range))
dt.author <- dt.books.range[dt.books.range$authors == author.name, ]
author.class <- dt.author$avg_rating_individual_class[1]
authors.similar.class <- unique(dt.books.range[dt.books.range$avg_rating_individual_class == author.class, ]$authors)
authors.similar.class <- authors.similar.class[authors.similar.class != author.name]
dt.author.similar.ranking <- cbind(authors = authors.similar.class, author = author.name)[1:top.n.values,]
g.books.ranking <- graph.data.frame(dt.author.similar.ranking, directed = FALSE)
plot(g.books.ranking)
}
plot.similar.category.authors <- function(author.name, year.range, top.n.values) {
dt.books.range <- filter(dt.books, published_year >= min(year.range) & published_year <= max(year.range))
dt.author <- dt.books.range[dt.books.range$authors == author.name, ]
author.main.category <- dt.author$main_category[1]
authors.similar.category <- unique(dt.books.range[dt.books.range$main_category == author.main.category, ]$authors)
authors.similar.category <- authors.similar.category[authors.similar.category != author.name]
dt.author.similar.category <- cbind(authors = authors.similar.category, author = author.name)[1:top.n.values,]
g.books.category<- graph.data.frame(dt.author.similar.category, directed = FALSE)
plot(g.books.category)
}
plot.similar.rank.category.authors <- function(author.name, year.range, top.n.values) {
dt.books.range <- filter(dt.books, published_year >= min(year.range) & published_year <= max(year.range))
dt.author <- dt.books.range[dt.books.range$authors == author.name, ]
author.class <- dt.author$avg_rating_individual_class[1]
author.main.category <- dt.author$main_category[1]
authors.similar.class <- unique(dt.books.range[dt.books.range$avg_rating_individual_class == author.class, ]$authors)
authors.similar.class <- authors.similar.class[authors.similar.class != author.name]
authors.similar.category <- unique(dt.books.range[dt.books.range$main_category == author.main.category, ]$authors)
authors.similar.category <- authors.similar.category[authors.similar.category != author.name]
authors.similar.class.category <- c(authors.similar.class, authors.similar.category)
#s? aparecem 30 autores
dt.authors.similar.class.category <- cbind(authors = authors.similar.class.category, author = author.name)[1:top.n.values,]
g.books.class.category<- graph.data.frame(dt.authors.similar.class.category, directed = FALSE)
plot(g.books.class.category)
}
# OVERALL NETWORKS
plot.similar.category.network <- function(year.range, top.n.values) {
dt.books.range <- filter(dt.books, published_year >= min(year.range) & published_year <= max(year.range))
dt.books.range$colors <- unname(setNames(dt.colors[,2], dt.colors[,1])[as.character(dt.books.range$categories)])
dt.top.50.authors.published <- as.data.table(dt.books.range)
dt.top.50.authors.published <- dt.top.50.authors.published[, n_books := .N, by="authors"]
top.50.authors.published <- unique(dt.top.50.authors.published[order(-n_books)]$authors)[1:top.n.values]
dt.50.authors.published <- dt.books.range[dt.top.50.authors.published$authors %in% top.50.authors.published, ]
dt.authors <- data.table(authors = unique(dt.50.authors.published$authors), type= TRUE)
dt.categories <- data.table(authors = unique(dt.50.authors.published$categories), type= FALSE)
dt.vertices <- rbind(dt.authors, dt.categories)
g <- graph.data.frame(dt.50.authors.published[c("authors","categories")], directed = FALSE, vertices = dt.vertices)
g.categories <- bipartite.projection(g)$proj2
plot(g.categories, edge.color=dt.books.range$colors)
legend(x = "bottomleft",
inset = c(-0.15, 0),
legend = c(keys(dict.colors.categories)) ,
lty = c(1, 2),
col = c(values(dict.colors.categories)),
lwd = 2,
pch=20,
cex = 0.7,
bty = "n",
xpd = TRUE)
#legend("bottomleft", legend=c(keys(dict.colors.categories))  , col = c(values(dict.colors.categories)) , bty = "n", pch=20 , pt.cex = 1, cex = 0.7, text.col="black", inset=c(0,0), xpd=TRUE)
}
plot.similar.rating.network <- function(year.range, top.n.values) {
dt.books.range <- filter(dt.books, published_year >= min(year.range) & published_year <= max(year.range))
dt.books.range$colors <- unname(setNames(dt.colors.avg.rating[,2], dt.colors.avg.rating[,1])[as.character(dt.books.range$avg_rating_class)])
dt.top.50.authors.published <- as.data.table(dt.books.range)
dt.top.50.authors.published <- dt.top.50.authors.published[, n_books := .N, by="authors"]
top.50.authors.published <- unique(dt.top.50.authors.published[order(-n_books)]$authors)[1:top.n.values]
dt.50.authors.published <- dt.books.range[dt.top.50.authors.published$authors %in% top.50.authors.published, ]
dt.authors <- data.table(authors = unique(dt.50.authors.published$authors), type= TRUE)
dt.rating <- data.table(authors = unique(dt.50.authors.published$avg_rating_class), type= FALSE)
dt.vertices <- rbind(dt.authors, dt.rating)
g <- graph.data.frame(dt.50.authors.published[c("authors","avg_rating_class")], directed = FALSE, vertices = dt.vertices)
g.rating <- bipartite.projection(g)$proj2
plot(g.rating, edge.color=dt.books.range$colors)
legend(x = "bottomleft",
inset = c(-0.15, 0),
legend = c(keys(dict.colors.rating)) ,
lty = c(1, 2),
col = c(values(dict.colors.rating)),
lwd = 2,
pch=20,
cex = 0.7,
bty = "n",
xpd = TRUE)
#legend("bottom", legend=c(keys(dict.colors.rating))  , col = c(values(dict.colors.rating)) , bty = "n", pch=20 , pt.cex = 1, cex = 0.7, text.col="black", horiz=T , inset=c(0, -.15), xpd=TRUE)
}
load("books.RData")
plot(pg)
df <- data.frame(a = c(0,1,2,3,4),b = c(3,4,5,6,7))
nod <- data.frame(node = c(0:7),wt = c(1:8))
pg <- graph_from_data_frame(d = df, vertices = nod,directed = F)
plot(pg)
plot(pg, edge.label = nod$wt)
plot.coauthor.network <- function() {
author.books <- unique(dt.author$title)
books.in.dt <- dt.books[dt.books$title %in% author.books, ]
books.in.dt.other <- books.in.dt[!books.in.dt$authors %in% author, ]
books.in.dt.other[,c("title", "authors")]
}
plot.coauthor.network("Agatha Christie")
author.books <- unique(dt.author$title)
dt.books
library(data.table)
library(ggplot2)
library(igraph)
library(shiny)
# library(readxl)
library(openxlsx)
dt.books <- read.xlsx("dt.books.clean.xlsx")
dt.books <- dt.books[,c("title", "authors", "categories", "published_year", "average_rating")]
# Creating the column avg_rating_class that tells for each BOOK the rating that they are in
dt.books$avg_rating_class <- with(dt.books, ifelse(average_rating >= 0 & average_rating < 0.5, "[0-0.5[", ifelse(average_rating >= 0.5 & average_rating < 1, "[0.5 -1[", ifelse(average_rating >= 1 & average_rating < 1.5, "[1-1.5[", ifelse(average_rating >= 1.5 & average_rating < 2, "[1.5-2[", ifelse(average_rating >= 2 & average_rating <= 2.5, "[2-2.5]", ifelse(average_rating >= 2.5 & average_rating <= 3, "[2.5-3[", ifelse(average_rating >= 3 & average_rating <= 3.5, "[3-3.5[", ifelse(average_rating >= 3.5 & average_rating <= 4,  "[3.5-4[", ifelse(average_rating >= 4 & average_rating <= 4.5,  "[4-4.5[", ifelse(average_rating >= 4.5 & average_rating <= 5,  "[4.5-5]", "NA")))))))))))
# Creating the column avg_rating_individual that tells for each AUTHOR the rating that they are in (by doing the average of all their books)
average.ratings <- vector()
for (author in dt.books$authors) {
the_author <- dt.books[dt.books$authors %in% author, ]
average_rating_author <- mean(the_author$average_rating)
average.ratings <- c(average.ratings, average_rating_author)
}
dt.books$avg_rating_individual <- average.ratings
# Creating the column avg_rating_individual_class that tells for each AUTHOR the rating that they are in (same as above but with new column)
dt.books$avg_rating_individual_class <- with(dt.books, ifelse(avg_rating_individual >= 0 & avg_rating_individual < 0.5, "[0-0.5[", ifelse(avg_rating_individual >= 0.5 & avg_rating_individual < 1, "[0.5 -1[", ifelse(avg_rating_individual >= 1 & avg_rating_individual < 1.5, "[1-1.5[", ifelse(avg_rating_individual >= 1.5 & avg_rating_individual < 2, "[1.5-2[", ifelse(avg_rating_individual >= 2 & avg_rating_individual <= 2.5, "[2-2.5]", ifelse(avg_rating_individual >= 2.5 & avg_rating_individual <= 3, "[2.5-3[", ifelse(avg_rating_individual >= 3 & avg_rating_individual <= 3.5, "[3-3.5[", ifelse(avg_rating_individual >= 3.5 & avg_rating_individual <= 4,  "[3.5-4[", ifelse(avg_rating_individual >= 4 & avg_rating_individual <= 4.5,  "[4-4.5[", ifelse(avg_rating_individual >= 4.5 & avg_rating_individual <= 5,  "[4.5-5]", "NA")))))))))))
main.categories <- vector()
for (author in dt.books$author) {
the_author <- dt.books[dt.books$authors %in% author, ]
main.category <- names(sort(table(the_author$categories), decreasing=TRUE)[1])
main.categories <- c(main.categories, main.category)
}
dt.books$main_category <- main.categories
set.seed(150)
dict.colors.categories <- hash()
for (category in unique(dt.books$categories)) {
dict.colors.categories[[category]] <- as.character(randomColor(luminosity="bright"))
}
dt.colors <- data.frame(Col1=c(keys(dict.colors.categories)), Col2=c(values(dict.colors.categories)),
stringsAsFactors=FALSE)
dict.colors.rating <- hash()
for (rating_class in unique(dt.books$avg_rating_class)) {
dict.colors.rating[[rating_class]] <- as.character(randomColor(luminosity="bright"))
}
dt.colors.avg.rating <- data.frame(Col1=c(keys(dict.colors.rating)), Col2=c(values(dict.colors.rating)),
stringsAsFactors=FALSE)
save(dt.colors, file="books.RData")
save(dt.books, file="books.RData")
setwd("C:/Users/Maria Ferreira/Desktop/NetworkAnalyticsShiny/NetworkAnalyticsProject")
